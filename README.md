<div align="center">

```ascii
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                           â•‘
â•‘     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—  â–ˆâ–ˆâ•—    â•‘
â•‘    â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘    â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘    â•‘
â•‘    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘    â•‘
â•‘    â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘    â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•  â•šâ•â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘    â•‘
â•‘    â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘    â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘    â•‘
â•‘    â•šâ•â•  â•šâ•â•â•šâ•â•    â•šâ•â•  â•šâ•â•â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â•â•šâ•â•  â•šâ•â• â•šâ•â•â•â•â•â•â•šâ•â•  â•šâ•â•    â•‘
â•‘                                                                           â•‘
â•‘            Deep Learning â€¢ Neural Architecture â€¢ Production AI            â•‘
â•‘                                                                           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

<img src="https://readme-typing-svg.demolab.com?font=Fira+Code&weight=600&size=22&duration=3000&pause=1000&color=00D9FF&center=true&vCenter=true&multiline=true&repeat=true&width=800&height=100&lines=Training+neural+networks+from+scratch;Deploying+AI+to+production+systems;Reading+arXiv+papers+at+2AM;Building+the+future+with+PyTorch" alt="Dynamic Status" />

</div>

---

## LIVE ENGINEERING METRICS

<div align="center">

<table>
<tr>
<td align="center">
<img src="https://github-readme-stats.vercel.app/api?username=siracgezgin&show_icons=true&theme=github_dark&hide_border=true&bg_color=0D1117&title_color=00D9FF&icon_color=00D9FF&text_color=FFFFFF&rank_icon=percentile&include_all_commits=true&count_private=true" width="495px" />
</td>
<td align="center">
<img src="https://github-readme-streak-stats.herokuapp.com?user=siracgezgin&theme=github-dark-blue&hide_border=true&background=0D1117&stroke=00D9FF&ring=00D9FF&fire=00D9FF&currStreakLabel=00D9FF&sideLabels=FFFFFF&dates=8B949E" width="495px" />
</td>
</tr>
</table>

<img src="https://github-profile-summary-cards.vercel.app/api/cards/profile-details?username=siracgezgin&theme=github_dark" width="100%" />

</div>

---

## ACTIVE RESEARCH PIPELINE

<div align="center">

```mermaid
%%{init: {'theme':'dark', 'themeVariables': { 'darkMode':'true', 'background':'#0D1117', 'primaryColor':'#00D9FF', 'primaryTextColor':'#fff', 'primaryBorderColor':'#00D9FF', 'lineColor':'#00D9FF', 'secondaryColor':'#161B22', 'tertiaryColor':'#0D1117'}}}%%
graph LR
    A[arXiv Papers] -->|Daily Reading| B(Research Notes)
    B -->|Implementation| C{PyTorch Experiments}
    C -->|Validation| D[Model Training]
    D -->|Optimization| E[Production Deployment]
    E -->|Monitoring| F[Performance Analysis]
    F -->|Iteration| B
    
    style C fill:#00D9FF,stroke:#00D9FF,stroke-width:3px,color:#000
    style E fill:#76B900,stroke:#76B900,stroke-width:2px,color:#fff
    style A fill:#EE4C2C,stroke:#EE4C2C,stroke-width:2px,color:#fff
```

</div>

### Current Focus Areas

<table>
<tr>
<td width="50%">

**Neural Implicit Representations**
```python
status = "Active Research"
reference = "arXiv:2110.10863"
implementation = "PyTorch from scratch"
application = "FEA optimization"
progress = "â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘ 70%"
```

</td>
<td width="50%">

**Industrial Computer Vision**
```python
project = "Light Guide QA System"
model = "YOLOv8-Pose"
deployment = "Real-time inference"
checkpoints = 24
latency = "<100ms"
```

</td>
</tr>
</table>

---

## TECHNOLOGY STACK & PROFICIENCY

<div align="center">

### Core ML/AI Frameworks

![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)
![TensorFlow](https://img.shields.io/badge/TensorFlow-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white)
![HuggingFace](https://img.shields.io/badge/ğŸ¤—_Transformers-FFD21E?style=for-the-badge)
![OpenCV](https://img.shields.io/badge/OpenCV-5C3EE8?style=for-the-badge&logo=opencv&logoColor=white)

### Computer Vision & 3D

![YOLOv8](https://img.shields.io/badge/YOLOv8-00FFFF?style=for-the-badge&logo=yolo&logoColor=black)
![Open3D](https://img.shields.io/badge/Open3D-FFFFFF?style=for-the-badge)
![CUDA](https://img.shields.io/badge/CUDA-76B900?style=for-the-badge&logo=nvidia&logoColor=white)

### Systems & Deployment

![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)
![C++](https://img.shields.io/badge/C++-00599C?style=for-the-badge&logo=cplusplus&logoColor=white)
![ROS](https://img.shields.io/badge/ROS-22314E?style=for-the-badge&logo=ros&logoColor=white)
![Docker](https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white)

</div>

<details>
<summary><b>View Detailed Skill Breakdown</b></summary>

<br/>

```python
skills = {
    "deep_learning": {
        "frameworks": ["PyTorch", "TensorFlow", "JAX"],
        "architectures": ["Transformers", "CNNs", "GNNs", "NeRF"],
        "techniques": [
            "Custom loss functions",
            "Model quantization",
            "Distributed training",
            "Neural architecture search"
        ],
        "proficiency": 0.92
    },
    "computer_vision": {
        "libraries": ["OpenCV", "Ultralytics", "Open3D", "MMDetection"],
        "applications": [
            "Object detection/tracking",
            "Pose estimation", 
            "3D reconstruction",
            "PointCloud processing"
        ],
        "proficiency": 0.88
    },
    "systems": {
        "languages": ["Python", "C++", "CUDA"],
        "optimization": ["TensorRT", "ONNX", "Model pruning"],
        "deployment": ["Docker", "FastAPI", "TorchServe"],
        "hardware": ["Jetson Nano", "NVIDIA GPUs"],
        "proficiency": 0.85
    },
    "robotics": {
        "frameworks": ["ROS/ROS2", "Gazebo", "PX4"],
        "algorithms": ["SLAM", "Path planning", "Swarm intelligence"],
        "proficiency": 0.80
    }
}
```

</details>

---

## RESEARCH & PRODUCTION WORK

### Martur Fompak International | AI R&D Lab
**October 2025 - Present** | Automotive Industry Research

<table>
<tr>
<td width="50%">

#### 3D Generative Design for FEA

**Problem Space**  
Traditional Finite Element Analysis is computationally expensive for topology optimization in automotive seat design.

**Research Approach**
- Neural implicit representations (arXiv:2110.10863)
- PyTorch implementation from first principles
- PointCloud processing pipeline (Open3D)
- Voronoi diagram integration for structural analysis

**Current Progress**
```
Literature Review    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 100%
Framework Mastery    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘  75%
Model Implementation â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  50%
Validation Pipeline  â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  20%
```

</td>
<td width="50%">

#### Light Guide Vision System

**Industrial Challenge**  
Real-time quality verification across 24 checkpoints on assembly line with <1s latency requirement.

**Solution Architecture**
- YOLOv8-Pose for operator action detection
- OpenCV preprocessing pipeline
- Custom procedural compliance classifier
- Hardware-optimized inference

**System Performance**
```
Detection Accuracy    98.7%
False Positive Rate   <0.5%
Inference Time       <100ms
System Uptime        99.8%
```

</td>
</tr>
</table>

---

## SELECTED PROJECTS & RESEARCH

<div align="center">

<table>
<tr>
<td width="33%" align="center">

### HomeOS-AI
**Edge AI Voice Assistant**

<img src="https://img.shields.io/badge/Status-Open_Source-success?style=flat-square" />
<img src="https://img.shields.io/badge/Hardware-Jetson_Nano-76B900?style=flat-square" />

Privacy-first LLM running on edge device. Zero cloud dependency, sub-second response times.

**Tech Stack**  
TinyLlama â€¢ Whisper â€¢ CUDA  
TensorRT â€¢ INT4 Quantization

**Latency**  
`Wake: 100ms | STT: 500ms | LLM: 200ms`

</td>
<td width="33%" align="center">

### TÃœBÄ°TAK 2209-A Research
**Restaurant Intelligence System**

<img src="https://img.shields.io/badge/Grant-TÃœBÄ°TAK-red?style=flat-square" />
<img src="https://img.shields.io/badge/Status-Active_Research-yellow?style=flat-square" />

End-to-end AI platform for data-driven restaurant operations and customer analytics.

**Tech Stack**  
Zemberek NLP â€¢ LSTM  
Collaborative Filtering â€¢ Scikit-learn

**Impact**  
Menu optimization â€¢ Demand forecasting  
Personalized recommendations

</td>
<td width="33%" align="center">

### TEKNOFEST Swarm UAV
**Autonomous Coordination**

<img src="https://img.shields.io/badge/Achievement-Finalist-gold?style=flat-square" />
<img src="https://img.shields.io/badge/Competition-HAVELSAN-orange?style=flat-square" />

Multi-drone swarm algorithms for GPS-denied environments with real-time coordination.

**Tech Stack**  
ROS2 â€¢ Gazebo â€¢ PX4  
C++ â€¢ Market-Based Allocation

**Features**  
Decentralized control â€¢ Formation flight  
Collision avoidance

</td>
</tr>
</table>

</div>

---

## GITHUB ACTIVITY ANALYSIS

<div align="center">

<img src="https://github-readme-activity-graph.vercel.app/graph?username=siracgezgin&bg_color=0D1117&color=00D9FF&line=00D9FF&point=FFFFFF&area=true&hide_border=true&custom_title=Commit%20Activity%20%7C%20Building%20AI%20Systems%20Daily" width="100%" />

<br/><br/>

<table>
<tr>
<td width="50%">
<img src="https://github-profile-summary-cards.vercel.app/api/cards/repos-per-language?username=siracgezgin&theme=github_dark" width="100%" />
</td>
<td width="50%">
<img src="https://github-profile-summary-cards.vercel.app/api/cards/most-commit-language?username=siracgezgin&theme=github_dark" width="100%" />
</td>
</tr>
<tr>
<td width="50%">
<img src="https://github-profile-summary-cards.vercel.app/api/cards/stats?username=siracgezgin&theme=github_dark" width="100%" />
</td>
<td width="50%">
<img src="https://github-profile-summary-cards.vercel.app/api/cards/productive-time?username=siracgezgin&theme=github_dark&utcOffset=3" width="100%" />
</td>
</tr>
</table>

</div>

---

## COMPETITIVE ACHIEVEMENTS

<div align="center">

| Year | Competition | Project | Result | Technology Stack |
|:----:|:-----------|:--------|:------:|:----------------|
| **2025** | TÃœBÄ°TAK 2209-A | Restaurant AI Intelligence | **Grant Awarded** | NLP â€¢ LSTM â€¢ ML |
| **2024** | TEKNOFEST Swarm UAV | Multi-Drone Coordination | **Finalist** | ROS2 â€¢ C++ â€¢ PX4 |
| **2023** | TEKNOFEST AI in Health | Medical Imaging Detection | Competitor | YOLOv8 â€¢ PyTorch |
| **2022** | TEKNOFEST Underwater | Autonomous Navigation | Competitor | OpenCV â€¢ Computer Vision |

</div>

---

## PROFESSIONAL NETWORK

<div align="center">

<table>
<tr>
<td align="center" width="33%">
<a href="https://linkedin.com/in/siracgezgin">
<img src="https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white" />
<br/>
<sub>Research Network</sub>
</a>
</td>
<td align="center" width="33%">
<a href="mailto:siracgezgin@gmail.com">
<img src="https://img.shields.io/badge/Email-D14836?style=for-the-badge&logo=gmail&logoColor=white" />
<br/>
<sub>siracgezgin@gmail.com</sub>
</a>
</td>
<td align="center" width="33%">
<a href="https://github.com/siracgezgin">
<img src="https://img.shields.io/badge/GitHub-181717?style=for-the-badge&logo=github&logoColor=white" />
<br/>
<sub>Open Source Portfolio</sub>
</a>
</td>
</tr>
</table>

<br/>

```python
class AIResearchEngineer:
    def __init__(self):
        self.name = "Sirac Gezgin"
        self.role = "AI Research Engineer @ Martur Fompak International"
        self.education = "Computer Engineering, BTU (2026)"
        self.focus = [
            "Neural Architecture Design",
            "Production AI Systems",
            "Edge AI Deployment",
            "Computer Vision"
        ]
    
    def current_work(self):
        return {
            "research": "Neural Implicit Representations for FEA",
            "production": "YOLOv8-based Quality Control System",
            "learning": "Advanced PyTorch internals & optimization",
            "reading": "arXiv papers on generative design"
        }
    
    def philosophy(self):
        return "Building AI systems that work in production, not just notebooks"

engineer = AIResearchEngineer()
```

<br/>

**Open to research collaborations in:**  
Deep Learning â€¢ Computer Vision â€¢ Generative AI â€¢ Edge AI â€¢ Robotics

</div>

---

<div align="center">

<img src="https://capsule-render.vercel.app/api?type=waving&color=gradient&customColorList=0,2,3,4,6&height=100&section=footer" />

</div>
